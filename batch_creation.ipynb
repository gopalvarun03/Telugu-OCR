{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import fasttext\n",
    "\n",
    "images_dir = '../teluguOCR/Dataset/Noised_Images/Image'\n",
    "Labels_dir = \"../teluguOCR/Dataset/strings.txt\"\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the txt file and read the file line by line.\n",
    "def read_file_lines(filename):\n",
    "    lines = []\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                lines.append(line.strip())  # Remove trailing newline characters\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "acchulu = ['అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ౡ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః']\n",
    "hallulu = ['క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
    "           'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
    "           'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
    "           'త', 'థ', 'ద', 'ధ', 'న',\n",
    "           'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
    "           'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ']\n",
    "vallulu = ['ా', 'ి', 'ీ', 'ు' , 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', 'ం', 'ః', 'ఁ', 'ౕ', 'ౖ', 'ౢ' ]\n",
    "connector = ['్']\n",
    "numbers = ['౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯']\n",
    "splcharacters= [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n",
    "              '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n",
    "              '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', 'ఽ']\n",
    "spl = splcharacters + numbers\n",
    "\n",
    "bases = acchulu + hallulu + spl\n",
    "vms = vallulu\n",
    "cms = hallulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bases:  108\n",
      "Vms:  19\n",
      "Cms:  36\n"
     ]
    }
   ],
   "source": [
    "acchulu = ['అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఌ', 'ౡ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః']\n",
    "hallulu = ['క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
    "           'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
    "           'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
    "           'త', 'థ', 'ద', 'ధ', 'న',\n",
    "           'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
    "           'య', 'ర', 'ల', 'వ', 'శ', 'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ']\n",
    "vallulu = ['ా', 'ి', 'ీ', 'ు' , 'ూ', 'ృ', 'ౄ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', 'ం', 'ః', 'ఁ', 'ౕ', 'ౖ', 'ౢ' ]\n",
    "connector = ['్']\n",
    "numbers = ['౦', '౧', '౨', '౩', '౪', '౫', '౬', '౭', '౮', '౯']\n",
    "splcharacters= [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')',\n",
    "              '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[',\n",
    "              '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '1','2', '3', '4', '5', '6', '7', '8', '9', '0', 'ఽ']\n",
    "spl = splcharacters + numbers\n",
    "\n",
    "bases = acchulu + hallulu + spl\n",
    "vms = vallulu\n",
    "cms = hallulu\n",
    "\n",
    "print(\"Bases: \", len(bases))\n",
    "print(\"Vms: \", len(vms))\n",
    "print(\"Cms: \", len(cms))\n",
    "\n",
    "characters = bases+vms+cms+connector\n",
    "\n",
    "base_mapping = {}\n",
    "i = 2\n",
    "for x in bases:\n",
    "  base_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "vm_mapping = {}\n",
    "i = 2\n",
    "for x in vms:\n",
    "  vm_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "cm_mapping = {}\n",
    "i = 2\n",
    "for x in cms:\n",
    "  cm_mapping[x] = i\n",
    "  i+=1\n",
    "\n",
    "  \n",
    "# creates a list of ductionaries with each dictionary reporesenting a term\n",
    "def wordsDicts(s):\n",
    "  List = []\n",
    "  for i in range(len(s)):\n",
    "    x = s[i]\n",
    "    prev = ''\n",
    "    if i > 0: prev = s[i-1]\n",
    "    #----------------------------------is it a base term-----------------------\n",
    "    if((x in acchulu or x in hallulu)  and prev != connector[0]):\n",
    "      List.append({})\n",
    "      List[-1]['base'] = x\n",
    "    #----------------------------if it is a consonant modifier-----------------\n",
    "    elif x in hallulu and prev == connector[0]:\n",
    "      if(len(List) == 0):\n",
    "        print(x)\n",
    "      if('cm' not in List[-1]): List[-1]['cm'] = []\n",
    "      List[len(List)-1]['cm'].append(x)\n",
    "\n",
    "      #---------------------------if it is a vowel modifier--------------------\n",
    "    elif x in vallulu:\n",
    "      if(len(List) == 0):\n",
    "        print(x)\n",
    "\n",
    "      if('vm' not in List[-1]): List[-1]['vm'] = []\n",
    "      List[len(List)-1]['vm'].append(x)\n",
    "\n",
    "      #----------------------------it is a spl character-----------------------\n",
    "    elif x in spl:\n",
    "      List.append({})\n",
    "      List[len(List)-1]['base'] = x\n",
    "    else:\n",
    "      continue\n",
    "  return List\n",
    "\n",
    "# def one_hot_encoder(s):\n",
    "#   List = wordsDicts(s)\n",
    "#   onehot = []\n",
    "#   for i in range(len(List)):\n",
    "#     D = List[i]\n",
    "#     onehotbase=  [0 for _ in range(len(acchulu) +  len(hallulu) + len(spl))]\n",
    "#     onehotvm1 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm2 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm3 =  [0 for _ in range(len(vallulu))]\n",
    "#     onehotvm4 =  [0 for _ in range(len(vallulu))]\n",
    "\n",
    "#     onehotcm1 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm2 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm3 =  [0 for _ in range(len(hallulu))]   \n",
    "#     onehotcm4 =  [0 for _ in range(len(hallulu))]   \n",
    "\n",
    "#     onehotbase[base_mapping[D['base']]-1] = 1\n",
    "\n",
    "#     it = 1\n",
    "#     if('vm' in D):\n",
    "#       for j in D['vm']:\n",
    "#         if it == 1:\n",
    "#           onehotvm1[vm_mapping[j]-1] = 1\n",
    "#         elif it == 2:\n",
    "#           onehotvm2[vm_mapping[j]-1] = 1\n",
    "#         elif it == 3:\n",
    "#           onehotvm3[vm_mapping[j]-1] = 1\n",
    "#         elif it == 4:\n",
    "#           onehotvm4[vm_mapping[j]-1] = 1\n",
    "#         it += 1\n",
    "    \n",
    "#     it = 1\n",
    "#     if('cm' in D):\n",
    "#       for j in D['cm']:\n",
    "#         if it == 1:\n",
    "#           onehotcm1[cm_mapping[j]-1] = 1\n",
    "#         elif it == 2:\n",
    "#           onehotcm2[cm_mapping[j]-1] = 1\n",
    "#         elif it == 3:\n",
    "#           onehotcm3[cm_mapping[j]-1] = 1\n",
    "#         elif it == 4:\n",
    "#           onehotcm4[cm_mapping[j]-1] = 1\n",
    "#         it += 1\n",
    "\n",
    "\n",
    "#     onehoti = onehotbase + onehotvm1 + onehotvm2 + onehotvm3 + onehotvm4 + onehotcm1 + onehotcm2 + onehotcm3 + onehotcm4 #size 112 + 4*21 + 4*40 = 356\n",
    "#     onehot.append(onehoti)\n",
    "#   encoded = torch.tensor(onehot).float().to(device)\n",
    "#   return encoded\n",
    "\n",
    "# def One_Hot_Decoder(List):\n",
    "#   x = \"\"\n",
    "#   for onehoti in List:\n",
    "#     for i in range(0, 112):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += bases[i]\n",
    "\n",
    "#     for i in range(196, 236):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-196]\n",
    "#     for i in range(236, 276):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-236]\n",
    "#     for i in range(276, 316):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-276]\n",
    "#     for i in range(316, 356):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += connector[0]\n",
    "#         x += cms[i-316]\n",
    "\n",
    "#     for i in range(112, 133):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-112]\n",
    "#     for i in range(133, 154):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-133]\n",
    "#     for i in range(154, 175):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-154]\n",
    "#     for i in range(175, 196):\n",
    "#       if onehoti[i] == 1:\n",
    "#         x += vms[i-175]\n",
    "#   return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_encoding(s):\n",
    "  List = wordsDicts(s)\n",
    "  onehot = []\n",
    "  for i in range(len(List)):\n",
    "    D = List[i]\n",
    "    onehotbase=  [1]\n",
    "    onehotvm1 =  [1]\n",
    "    onehotvm2 =  [1]\n",
    "    onehotvm3 =  [1]\n",
    "    onehotvm4 =  [1]\n",
    "    onehotcm1 =  [1]\n",
    "    onehotcm2 =  [1]\n",
    "    onehotcm3 =  [1]\n",
    "    onehotcm4 =  [1]\n",
    "\n",
    "\n",
    "    onehotbase[0] = base_mapping[D['base']]\n",
    "\n",
    "    it = 1\n",
    "    if('vm' in D):\n",
    "      for j in D['vm']:\n",
    "        if it == 1:\n",
    "          onehotvm1[0] = vm_mapping[j]\n",
    "        elif it == 2:\n",
    "          onehotvm2[0] = vm_mapping[j]\n",
    "        elif it == 3:\n",
    "          onehotvm3[0] = vm_mapping[j]\n",
    "        elif it == 4:\n",
    "          onehotvm4[0] = vm_mapping[j]\n",
    "        it += 1\n",
    "    \n",
    "    it = 1\n",
    "    if('cm' in D):\n",
    "      for j in D['cm']:\n",
    "        if it == 1:\n",
    "          onehotcm1[0] = cm_mapping[j]\n",
    "        elif it == 2:\n",
    "          onehotcm2[0] = cm_mapping[j]\n",
    "        elif it == 3:\n",
    "          onehotcm3[0] = cm_mapping[j]\n",
    "        elif it == 4:\n",
    "          onehotcm4[0] = cm_mapping[j]\n",
    "        it += 1\n",
    "    onehoti = onehotbase + onehotvm1 + onehotvm2 + onehotvm3 + onehotvm4 + onehotcm1 + onehotcm2 + onehotcm3 + onehotcm4 #size 110 + 4*21 + 4*38 = 346\n",
    "    onehot.append(onehoti)\n",
    "  return onehot\n",
    "\n",
    "def index_decoder(List):\n",
    "  x = \"\"\n",
    "  for onehoti in List:\n",
    "    if onehoti[0] > 1:\n",
    "      x += bases[onehoti[0]-2]\n",
    "\n",
    "    if onehoti[5] > 1:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[5]-2]\n",
    "    if onehoti[6] > 1:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[6]-2]\n",
    "    if onehoti[7] > 1:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[7]-2]\n",
    "    if onehoti[8] > 1:\n",
    "      x += connector[0]\n",
    "      x += cms[onehoti[8]-2]\n",
    "\n",
    "    if onehoti[1] > 1:\n",
    "      x += vms[onehoti[1]-2]\n",
    "    if onehoti[2] > 1:\n",
    "      x += vms[onehoti[2]-2]\n",
    "    if onehoti[3] > 1:\n",
    "      x += vms[onehoti[3]-2]\n",
    "    if onehoti[4] > 1:\n",
    "      x += vms[onehoti[4]-2]\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'అందరికి శుభాకాంక్షలు'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"అందరికి శుభాకాంక్షలు\"\n",
    "encoded = index_encoding(s)\n",
    "print(len(encoded))\n",
    "print(len(encoded[0]))\n",
    "index_decoder(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 40, 296])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'jhvbhvb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m line \u001b[38;5;241m=\u001b[39m lines[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mjhvbhvb\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m800\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jhvbhvb' is not defined"
     ]
    }
   ],
   "source": [
    "lines = read_file_lines(\"/home/ocr/teluguOCR/Dataset/final_strings.txt\")\n",
    "\n",
    "a = b = 0\n",
    "\n",
    "index = 1\n",
    "for i in range(1, 189531 + 1):\n",
    "    image = torch.load(\"/home/ocr/teluguOCR/Dataset/Noised_Images/Image\" + str(i) + \".pt\")\n",
    "    line = lines[i-1]\n",
    "    if(image.shape[1] > 800):\n",
    "        continue\n",
    "    if line[0] not in bases:\n",
    "        continue\n",
    "    label = index_encoding(line)\n",
    "    label = torch.tensor(label)\n",
    "    image = 255 - image\n",
    "\n",
    "    a, b = max(a, image.shape[1]), max(b, label.shape[0])\n",
    "\n",
    "    torch.save(image, \"/home/ocr/teluguOCR/Dataset/Cropped_Dataset/Images/Image\" + str(index) + \".pt\")\n",
    "    torch.save(label, \"/home/ocr/teluguOCR/Dataset/Cropped_Dataset/Labels/Label\" + str(index) + \".pt\")\n",
    "    print(index, end = '\\r')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800  |  158\n"
     ]
    }
   ],
   "source": [
    "print(a, \" | \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# LIST_Ten = torch.tensor(LIST)\n",
    "\n",
    "# print(LIST_Ten.shape)\n",
    "\n",
    "# # Plotting the distribution of lengths\n",
    "# plt.hist(LIST_Ten[:, 1], bins=100)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teluguOCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
